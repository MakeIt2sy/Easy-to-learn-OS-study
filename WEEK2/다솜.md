# CHAPTER 02 컴퓨터의 구조와 성능 향상

# 컴퓨터의 구성

## 컴퓨터의 기본 구성

- 필수 장치: 중앙 처리 장치(CPU), 메인메모리
- 주변 장치: 입력 장치, 출력 장치, 저장 장치

<br>

## 폰 노이만 구조

참고: [https://ko.wikipedia.org/wiki/폰_노이만_구조](https://ko.wikipedia.org/wiki/%ED%8F%B0_%EB%85%B8%EC%9D%B4%EB%A7%8C_%EA%B5%AC%EC%A1%B0)

![https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Von_Neumann_Architecture.svg/1200px-Von_Neumann_Architecture.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Von_Neumann_Architecture.svg/1200px-Von_Neumann_Architecture.svg.png)

처리 장치와 컨트롤 유닛을 포함하는 CPU, 데이터와 명령어를 저장하는 메모리, 외부 저장장치, 입출력장치가 버스로 연결되어 있는 구조

폰 노이만 구조 등장 이전의 컴퓨터들은 전선을 연결하여 회로를 구성하는 방식(하드와이어링)이었으므로, 다른 용도로 사용하려면 전선의 연결 구조를 바꿔야 했다. 이러한 불편을 해결하기 위해 폰 노이만은 하드웨어는 그대로 둔 채 작업할 프로그램만 교체해서 메모리에 올리는 구조를 제안했다.

폰 노이만 구조의 가장 큰 특징은 ‘모든 프로그램은 메모리에 올라와야 실행될 수 있다’는 것이다. 최초의 폰 노이만 구조 컴퓨터인 EDSAC 제작 이후에 나온 모든 컴퓨터는 모두 폰 노이만의 설계를 기본 구조로 디자인된다.

<br>

## CPU

참고: [https://ko.wikipedia.org/wiki/중앙_처리_장치](https://ko.wikipedia.org/wiki/%EC%A4%91%EC%95%99_%EC%B2%98%EB%A6%AC_%EC%9E%A5%EC%B9%98)

![https://upload.wikimedia.org/wikipedia/commons/d/d8/ABasicComputer.gif](https://upload.wikimedia.org/wikipedia/commons/d/d8/ABasicComputer.gif)

CPU는 ALU, Register, Control Unit, 내부 버스 등으로 이루어져 있다. 

ALU(산술 논리 연산 장치): 비교·판단·연산을 한다.

Register: CPU에서 처리할 명령어를 저장한다.

Control Unit: 명령어의 해석과 올바른 실행을 위해 CPU를 내부적으로 제어한다.

### CPU의 명령어 처리 과정

```c
int address1 = 2, address2 = 3, address3 = 0;
address3 = address1 + address2;
```

address1, address2, address3는 데이터를 저장할 수 있는 메모리 주소의 다른 이름으로, 메모리 주소를 외우기 어렵기 때문에 주소 대신 적당한 이름을 만들어 붙인 것이다.

아래는 위의 덧셈 프로그램을 어셈블리어로 변환한 코드이다.

```nasm
// 메모리의 100번지(Address1)에 있는 값을 레지스터 1로 가져온다.
LOAD mem(100), register 1;

// 메모리의 120번지(Address2)에 있는 값을 레지스터 2로 가져온다.
LOAD mem(120), register 2;

// 레지스터 1과 레지스터 2에 저장된 값을 더한 결과를 레지스터 10에 넣는다.
ADD register 10, register 1, register 2;

// 레지스터 10의 값을 메모리의 160번지로 옮긴다.
MOVE register 10, mem(160);
```

위의 덧셈 프로그램을 그림으로 나타내면 다음과 같다.

![CPU_명령어_처리_과정.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d5dbc1ec-2150-4de3-aeb3-ebb74cf24708/CPU_%EB%AA%85%EB%A0%B9%EC%96%B4_%EC%B2%98%EB%A6%AC_%EA%B3%BC%EC%A0%95.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230104%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230104T114432Z&X-Amz-Expires=86400&X-Amz-Signature=e945ae41eeae5af4de59c59373352e9b003f2569d53839d2b58fd5b4db7090cf&X-Amz-SignedHeaders=host&response-content-disposition=filename%3D%22CPU_%25EB%25AA%2585%25EB%25A0%25B9%25EC%2596%25B4_%25EC%25B2%2598%25EB%25A6%25AC_%25EA%25B3%25BC%25EC%25A0%2595.png%22&x-id=GetObject)

1. CU의 제어 신호에 따라 메모리에서 레지스터로 100번지(address1), 120번지(address2)의 값을 로드한다.
2. CU의 제어 신호에 따라 레지스터 1과 레지스터 2의 값을 더해 그 결과값을 레지스터 10에 저장한다.
3. CU의 제어 신호에 따라 레지스터 10에 있는 값을 메모리의 160번지로 옮긴다.

<br>

### 레지스터의 종류

CPU는 필요한 데이터를 메모리에서 가져와 레지스터에 저장하고 ALU를 이용하여 연산한 후 그 결과를 다시 레지스터에 저장했다가 메모리로 옮긴다. 이때 사용되는 레지스터가 데이터 레지스터와 주소 레지스터이다. 이 레지스터들은 사용자 프로그램에 의해 변경될 수 있기 때문에 사용자 가시 레지스터라고 부른다.

- 데이터 레지스터(Data Register): 메모리에서 가져온 데이터를 임시로 보관할 때 사용한다. CPU에 있는 대부분의 레지스터가 데이터 레지스터이므로 일반 레지스터, 범용 레지스터 등으로도 불린다.
- 주소 레지스터(Address Register): 데이터 또는 명령어가 저장된 메모리의 주소이다.

데이터 레지스터와 주소 레지스터 외에 특수 레지스터라는 게 있다. 특수 레지스터에는 프로그램 카운터, 명령어 레지스터, 메모리 주소 레지스터, 메모리 버퍼 레지스터 등이 있다.

- PC(Program Counter, 프로그램 카운터): 다음에 실행할 명령어의 주소를 기억하고 있다가 CU에 알려준다. 다음에 실행할 명령어의 주소를 가리키기 때문에 명령어 포인터라고도 불린다.
- IR(Instruction Regitser, 명령어 레지스터): 현재 실행 중인 명령어를 저장한다. CU는 IR에 있는 명령을 해석한 후 외부 장치에 적절한 제어 신호를 보낸다.
- MAR(Memory Address Register, 메모리 주소 레지스터): 메모리에서 데이터를 가져오거나 반대로 메모리로 데이터를 보낼 때 주소를 지정하기 위해 사용한다. 명령어를 처리하는 과정에서 필요한 메모리 주소를 이 레지스터에 넣으면 메모리 관리자가 이를 인식하여 해당 메모리 위치의 데이터를 가져오거나 해당 메모리 위치에 데이터를 저장한다.
- MBR(Memory Buffer Register, 메모리 버퍼 레지스터): 메모리에서 가져온 데이터나 메모리로 옮겨 갈 데이터를 임시로 저장한다. 항상 MAR과 함께 동작한다.

그 외에 프로그램 상태 레지스터가 있다.

- PSR(Program Status Register, 프로그램 상태 레지스터): ALU와 연결되어 있으며 연산 결과의 양수 여부, 음수 여부, 0여부, 자리 올림 유무 등을 저장한다.

<br>

### 특수 레지스터의 활용

LOAD mem(100), register 1의 실행 과정을 그림으로 나타내면 다음과 같다.

![LOAD_명령어_실행_과정.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5c44364f-5e0b-4e0c-a63f-e21f10723fce/LOAD_%EB%AA%85%EB%A0%B9%EC%96%B4_%EC%8B%A4%ED%96%89_%EA%B3%BC%EC%A0%95.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230104%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230104T114530Z&X-Amz-Expires=86400&X-Amz-Signature=088e5de750f8cc72c47edf6412850bd37f6857cf38d8591a60afb7bac489513a&X-Amz-SignedHeaders=host&response-content-disposition=filename%3D%22LOAD_%25EB%25AA%2585%25EB%25A0%25B9%25EC%2596%25B4_%25EC%258B%25A4%25ED%2596%2589_%25EA%25B3%25BC%25EC%25A0%2595.png%22&x-id=GetObject)

1. PC에 현재 실행 중인 코드의 행 번호 1이 저장되고, 이 번호는 CU에 전송된다. IR에 ‘LOAD mem(100), register 1’ 중 LOAD가 탑재된다.
2. CU가 IR에 있는 명령을 해석하여 메모리에 있는 데이터를 가져오라는 제어 신호를 보낸다.
3. MAR에 메모리 주소인 100이 저장되고, 메모리 관리자는 메모리 100번지에 저장된 값인 1을 MBR로 가져온다.
4. CU는 MBR에 저장된 값을 레지스터 1로 옮긴다.

<br>

### 버스의 종류

참고: [https://en.wikipedia.org/wiki/Bus_(computing)#Address_bus](https://en.wikipedia.org/wiki/Bus_(computing)#Address_bus)

![https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Computer_system_bus.svg/1200px-Computer_system_bus.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Computer_system_bus.svg/1200px-Computer_system_bus.svg.png)

버스는 CPU, 메모리, 주변장치 간 데이터를 주고받을 때 사용한다.

- 제어 버스: 다음에 어떤 작업을 할지 지시하는 제어 신호가 오고 간다. 제어 버스의 신호는 CPU, 메모리, 주변 장치와 양방향으로 오고 간다.
- 주소 버스: 메모리의 데이터를 읽거나 쓸 때 어느 위치에서 작업할 것인지를 알려주는 주소가 오고 간다. CPU에서 메모리나 주변장치로 나가는 주소 정보는 있지만 주소 버스를 통해 CPU로 전달되는 정보는 없다.
- 데이터 버스: 제어 버스가 다음에 어떤 작업을 할지 신호를 보내고 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다. 데이터 버스는 메모리 버퍼 레지스터와 연결되어 있으며 데이터의 이동이 양방향으로 이루어진다.

버스의 대역폭: 한 번에 전달할 수 있는 데이터의 최대 크기. CPU가 한 번에 처리할 수 있는 데이터의 크기와 같다. 64bit CPU의 경우 한 번에 처리할 수 있는 데이터의 최대 크기가 64bit인 것으로, 이 경우 레지스터의 크기와 버스의 대역폭 모두 64bit이다. 이 한 번에 처리할 수 있는 데이터의 최대 크기를 1 워드라고 한다.

<br>

## 메모리

모든 프로그램은 메모리에 올라와야 실행될 수 있다. 메모리에는 실행에 필요한 프로그램과 데이터가 존재하며, CPU와 협업하여 작업이 이뤄진다. 메모리 주소는 바이트 단위로 지정되고, 메모리에서 데이터를 읽거나 쓸 때는 워드 단위로 처리한다.

### 메모리의 종류

- RAM(Random Access Memory): 전력이 끊기면 데이터가 사라진다.
    - 휘발성 메모리
        - DRAM(Dynamic RAM): 저장된 0과 1의 데이터가 일정 시간이 지나면 사라지기 때문에 일정 시간마다 다시 재생시켜야 한다. 일반적으로 메인메모리에 사용된다.
        - SRAM(Static RAM): 전력이 공급되는 동안에는 데이터를 보관할 수 있어 재생할 필요가 없어 속도가 빠르다. 대신 가격이 비싸다. 일반적으로 캐시 같은 고속 메모리에 사용된다.
        - SDRAM(Synchronous Dynamic RAM): DRAM이 발전된 형태이다. 클록틱이 발생할 때마다 데이터를 저장하는 동기 DRAM이다.
        - DDR SRAM
    - 비휘발성 메모리
        - 플래시 메모리: 각 소자의 최대 사용 횟수가 제한되어 보통 소자 하나당 몇 천 번에서 만 번 정도 사용하면 제 기능을 못한다.
        - FRAM
        - PRAM
        - SSD: 플래시 메모리를 사용하여 HDD를 에뮬레이트한다.
- ROM(Read Only Memory): 전력이 끊겨도 데이터를 보관할 수 있지만 데이터를 한 번 저장하면 바꿀 수 없다. 바이오스를 저장한다.
    - 마스크 롬: 데이터를 지우거나 쓸 수 없다.
    - PROM: 전용 기계를 이용하여 데이터를 한 번만 저장할 수 있따.
    - EPROM: 데이터를 여러 번 쓰고 지울 수 있다.

❓ **메인 메모리를 비휘발성으로 만들면 전력이 끊겨도 내용이 남기 때문에 편리할 것 같은데, 메모리를 휘발성으로 만드는 이유는?**

비휘발성 메모리는 전력이 끊겨도 데이터를 보관해야 하므로 메모리 내부가 복잡하고 속도가 느리며 가격이 비싸기 때문에 아직 휘발성으로 만들어진다.

### 메모리 보호

현대 운영체제에서 메모리가 보호되지 않으면 어떤 작업이 다른 작업의 영역을 침범하여 프로그램을 파괴하거나 데이터를 지울 수 있다. 만약 다른 작업이 운영체제라면 시스템이 멈출 수도 있다.

운영체제도 하나의 소프트웨어이므로, 사용자의 작업이 진행되는 동안에는 운영체제의 작업이 중단된다. 이런 상황에서 사용자의 작업으로부터 운영체제를 보호하기 위해서는 하드웨어의 도움이 필요하다. 이를 위한 하드웨어로 경계 레지스터와 한계 레지스터가 있다.

- 경계 레지스터: 현재 진행 중인 작업의 메모리 시작 주소
- 한계 레지스터: 현재 진행 중인 작업이 차지하고 있는 메모리의 크기이다. 즉, ‘현재 진행 중인 작업의 메모리 마지막 주소 - 시작 주소’이다.

사용자의 작업이 진행되는 동안 두 레지스터의 주소 범위를 벗어나는지 하드웨어적으로 점검하여 메모리를 보호한다. 구체적으로, 현재 작업에서 데이터를 읽거나 쓸 때마다 CPU가 해당 작업이 경계 레지스터와 한계 레지스터의 주소값 안에서 이루어지는지 검사한다. 만약 두 레지스터의 값을 벗어난다면 메모리 오류와 관련된 인터럽트가 발생한다.  

### 부팅

컴퓨터를 켰을 때 운영체제를 메모리에 올리는 과정이다. 그 과정은 다음과 같다.

1. 사용자가 컴퓨터의 전원을 켠다. 
2. 롬에 저장된 바이오스가 실행된다. 바이오스는 하드웨어 작동을 점검한다. 만약 이상이 있다면 오류 메시지를 출력한다.
3. 하드디스크의 마스터 부트 레코드에 저장된 부트스트랩을 메모리로 가져와 실행한다.
4. 부트스트랩이 메모리에 올라오면 하드디스크에 저장된 운영체제를 메모리로 불러온다.
5. 메모리에 올라온 운영체제가 실행된다.

# 컴퓨터 성능 향상 기술

## 버퍼

속도의 차이가 있는 두 장치 사이의 속도 차이를 완화한다. 입출력장치에서 데이터를 가져올 때 한 번에 하나씩 전송하면 한 번에 전송되는 데이터 양이 적어 전송을 여러 번 해야 하므로 비효율적이다. 만약 이 경우에 버퍼를 사용한다면, 일정량의 데이터를 모아 한 번에 전송하기 때문에 전송 횟수가 줄어들어 효율적이다. 이런 식으로 일정량의 데이터를 모아 전송함으로써 속도 차이를 완화하는 장치가 버퍼이다.

예시

- 같은 사양의 하드디스크라면 버퍼의 용량이 큰 게 더 빠르다.
- 동영상 스트리밍 시, 동영상이 재생되는 도중 다음 데이터가 도착하지 않으면 동영상이 끊긴다. 이러한 현상을 방지하기 위해 데이터의 일부분을 버퍼에 넣어둔 후 동영상이 재생되게 한다.

### 스풀

CPU와 입출력장치가 독립적으로 동작하도록 고안된 소프트웨어적인 버퍼이다.

**스풀러**

프린터에 사용된다. 인쇄할 내용을 순차적으로 출력하는 소프트웨어이다. 출력 명령을 내린 프로그램과 독립적으로 동작한다.

워드프로세서로 작업하고 그 결과물을 프린터로 출력한다고 할 때, 스풀러가 없다면 모든 출력을 워드프로세서가 알아서 처리해야 하므로 인쇄가 끝날 때까지 워드프로세서를 사용할 수 없다. 만약 스풀러를 사용한다면, 인쇄할 내용을 하드디스크의 스풀러 공간에 저장하고 워드프로세서로는 문서 작업 등 다른 작업을 할 수 있다.

스풀러와 기존의 버퍼와의 차이점은, 버퍼의 경우 버퍼가 차야 이동이 시작되지만, 스풀러의 경우 한 인쇄물이 완료될 때까지 다른 인쇄물이 끼어들 수 없다.

## 캐시

메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다. CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 가져다놓는 공간이며, 필요한 데이터를 한꺼번에 모아 전달하므로 버퍼의 일종이다.

CPU는 메모리에 접근해야 할 때 메모리에 접근하기 전에 캐시에 먼저 접근하여 원하는 데이터가 있는지 확인한다. 만약 원하는 데이터가 있다면 캐시 히트, 없다면 캐시 미스이다.

<aside>
💡 **캐시 적중률을 높이는 방법**
1. 캐시의 크기를 늘린다.
2. 앞으로 많이 사용될 데이터를 가져온다. (지역성의 원리 사용)

</aside>

### 지역성의 원리

캐시 적중률을 극대화시키기 위해 사용하는 것으로, 모든 코드나 데이터에 균등하게 접근하지 않는다는 특성을 기본으로 한다.

- 시간 지역성: 최근에 참조된 주소의 내용이 또다시 참조될 확률이 높다.
- 공간 지역성: 참조된 주소와 인접한 주소의 내용이 다시 참조될 확률이 높다.

**❓ 프로그래밍 시 goto문을 사용하면 안되는 이유?**

지역성 이론에 따라 미리 가져온 데이터가 쓸모없어지기 때문이다.

**❓ 지역성의 관점에서 퀵 소트 VS 머지 소트 성능 비교**

참고: [https://medium.com/pocs/locality의-관점에서-quick-sort가-merge-sort보다-빠른-이유-824798181693](https://medium.com/pocs/locality%EC%9D%98-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C-quick-sort%EA%B0%80-merge-sort%EB%B3%B4%EB%8B%A4-%EB%B9%A0%EB%A5%B8-%EC%9D%B4%EC%9C%A0-824798181693)

효율적인 정렬을 위해서는, 캐시의 페이지 교체가 자주 일어나지 않는 것이 좋다. 왜냐하면, 캐시에 없는 데이터를 매번 물리 메모리에서 가져오는 데에 많은 시간이 들기 때문이다.

퀵 소트: 정렬 시, 최근에 참조한 데이터를 다시 참조하는 일이 잦고, 최근에 참조한 데이터와 인접한 데이터를 참조하는 일이 잦다. 이 때문에 캐시의 지역성이 높고, 페이지 변경이 머지 소트보다 덜 일어난다.

머지 소트: 정렬 시, 데이터의 처음부터 끝까지를 매번 왔다갔다하면서 데이터를 탐색한다. 이 때문에 캐시의 지역성이 낮고, 페이지 변경이 퀵 소트보다 더 자주 일어난다.

캐시의 지역성 관점에서 봤을 때, 퀵 소트의 성능이 더 좋다.

## 저장장치의 계층 구조

참고: [https://ko.wikipedia.org/wiki/메모리_계층_구조](https://ko.wikipedia.org/wiki/%EB%A9%94%EB%AA%A8%EB%A6%AC_%EA%B3%84%EC%B8%B5_%EA%B5%AC%EC%A1%B0)

![https://upload.wikimedia.org/wikipedia/commons/c/c6/%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B3%84%EC%B8%B5%EA%B5%AC%EC%A1%B0%EA%B7%B8%EB%A6%BC1.png](https://upload.wikimedia.org/wikipedia/commons/c/c6/%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B3%84%EC%B8%B5%EA%B5%AC%EC%A1%B0%EA%B7%B8%EB%A6%BC1.png)

위로 갈수록 속도가 빨라지고 비싸진다.

중복되는 데이터의 일관성을 유지하기 어렵다. CPU가 캐시에 저장된 데이터를 변경하면 메모리의 해당 주소에 있는 데이터도 갱신되어야 한다. 지연 쓰기를 할 경우, 쓰기가 완료되기 전 협업 중인 다른 컴퓨터에서 해당 데이터를 읽으면 데이터의 일관성이 사라질 수 있고, 컴퓨터의 전원이 꺼진다면 데이터를 잃어버릴 수 있다.

## 인터럽트

> **참고 자료**
운영체제와 정보기술의 원리 64p~65p, 70p~72p
[https://youtu.be/V4lp6iGoUFY](https://youtu.be/V4lp6iGoUFY)
[https://raisonde.tistory.com/entry/인터럽트Interrupt의-개념과-종류](https://raisonde.tistory.com/entry/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8Interrupt%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%A2%85%EB%A5%98)
[https://blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=brad903&logNo=221210044478](https://blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=brad903&logNo=221210044478)
> 

CPU가 프로그램을 실행하는 도중, **주변장치들이 CPU의 서비스를 필요로 하게 될 때** 그 **서비스를 요청하기 위해** 발생시키는 신호이다. 인터럽트가 발생하면, CPU는 자신에게 주어진 작업을 잠시 멈추고 인터럽트를 통해 요청된 서비스를 수행한다. CPU가 인터럽트 처리를 마친 후에는, 원래 하던 작업을 마저 한다.

인터럽트가 들어왔을 때 해야 할 일을 인터럽트 처리 루틴이라 한다. 인터럽트 처리 루틴에는 다양한 인터럽트에 대한 각각의 처리해야 할 일들이 정의되어 있다. 이 처리 루틴은 커널 내에 포함되어 있다.

인터럽트의 종류에는 하드웨어 인터럽트(외부 인터럽트, 내부 인터럽트)와 소프트웨어 인터럽트가 있다.

### 외부 인터럽트

- Power Fail Interrupt: 정전, 파워 이상 등
- Machine Check Interrupt: CPU의 기능적인 오류
- External interrupt
    - 자원이 할당된 시간이 끝난 경우
    - 키보드로 인터럽트 키를 누른 경우(Control + Alt + Delete 등)
    - 외부장치로부터 인터럽트 요청이 있는 경우
- I/O Interrupt
    - 입출력 장치가 데이터 전송을 요구하거나, 입출력 장치로부터의 데이터 전송이 끝나 다음 동작이 수행되어야 할 경우
    - 입출력 데이터에 이상이 있는 경우

### 내부 인터럽트

Trap이라고도 부른다. 잘못된 명령이나 잘못된 데이터를 사용할 때 발생한다.

- Program Check Interrupt
    - Division by zero: 컴퓨터는 마이너스 연산을 통해 나누기 연산을 한다. 어떤 수에서 0을 빼는 것은 아무리 반복해도 수가 변하지 않기 때문에, 인터럽트 처리를 하지 않으면 CPU가 폭발해버린다.
    - Overflow/Underflow
    - 기타 Exception

### 소프트웨어 인터럽트

프로그램 처리 중 명령의 요청에 의해 발생한다.

- 사용자가 프로그램을 실행시킬 때, 그 프로그램에서 SVC(SuperVisor Call)하는 경우
    - 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.
    - SuperVisor Call: CPU에게 CPU 제어권을 SuperVisor 프로그램에게 넘길 것을 지시하는 프로세서 명령어

### **인터럽트 동작 과정⭐⭐**

1. 인터럽트 요청
2. 프로그램 실행 중단: 현재 실행중인 CPU의 연산을 일시정지한다.
3. 현재 프로그램 상태 보존(백업): PCB, PC 등을 이용한다.
4. 인터럽트 처리 루틴 실행: 인터럽트를 요청한 장치를 식별하여 그에 맞는 인터럽트 처리 루틴을 찾아 실행한다.
5. 인터럽트 서비스 루틴 실행: 인터럽트의 원인을 파악하고 실질적인 작업을 수행한다. 이 때 인터럽트 플래그를 0으로 하면 추가 인터럽트 발생을 방지할 수 있다.
6. 상태 복구: 인터럽트 발생 시 저장해둔 PC를 복구한다.
7. 중단된 프로그램 실행 재개: 인터럽트 발생 시 저장해둔 PCB 값을 이용하여 이전에 실행중이던 프로그램을 이어서 실행한다.

### 인터럽트 우선순위

여러 장치에서 인터럽트가 동시에 발생하거나, 인터럽트 서비스 루틴 실행 중 다른 인터럽트가 발생할 경우 아래의 우선순위에 따라 인터럽트를 수행한다. 일반적으로 하드웨어 인터럽트가 소프트웨어 인터럽트보다 우선순위가 높고, 내부 인터럽트의 우선순위보다 외부 인터럽트의 우선순위가 높다.

Power Fail > Machine Check > External > I/O > 잘못된 명령 > Program Check > SVC(SuperVisor Call)

### 인터럽트 우선순위 판별 방법

**소프트웨어적인 방법(Polling)**: ****인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 해당하는 인터럽트 서비스 루틴을 수행하는 방법이다. 하드웨어 장치의 상태를 수시로 체크하여 명령을 받을 수 있는지 확인한다.

- 우선순위 변경이 쉽다.
- 인터럽트의 수가 많을 경우 하드웨어적인 방법에 비해 우선순위 판단 속도가 느리다.
- 회로가 간단하고 융통성이 있다.
- 별도의 하드웨어가 필요 없다.

**하드웨어적인 방법(Interrupt)**: CPU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일적한 동작을 한다.

- 소프트웨어적인 방법에 비해 비경제적이다.
- 회로가 복잡하고 융통성이 없다.
- 별도의 소프트웨어가 필요없이 하드웨어로 처리되므로, 속도가 빠르다.
- 폴링에 비해 신속한 대응이 가능하므로, 실시간 대응이 필요할 때 필수적이다.

- Daisy Chain
    - 인터럽트가 발생하는 모든 장치를 하나의 직렬 회선으로 연결한다.
    - 우선순위가 높은 장치를 상위에 두는 형태로 우선순위 차례대로 배치한다.
- 병렬 우선순위 부여 방식
    - 인터럽트 요청 회선이 여러 개일 때, 우선 순위를 병렬로 처리할 수 있는 경우를 말한다.
    - 현재 처리 중인 인터럽트와 요청된 인터럽트를 비교하여 요청된 인터럽트의 우선순위가 더 높으면 요청된 것을 먼저 처리하고 그렇지 않으면 기존 인터럽트를 처리한다.
    - CPU에 있는 인터럽트 레지스터의 각 비트는 요청 회선과 연결되어 있다.
    - 인터럽트 처리 루틴 없이 인터럽트 서비스 루틴이 시작된다.
    - 우선 순위가 낮은 요청을 비활성화시키는 마스크 레지스터를 갖고 있다.

<aside>
💡 **인터럽트 VS 폴링**
참고: [https://jaebworld.tistory.com/27](https://jaebworld.tistory.com/27)
****인터럽트를 사용하면 CPU 연산과 I/O 장치 작업을 중첩시켜 수행할 수 있다. 때문에 인터럽트 방식은 폴링 방식보다 CPU의 사용률을 높일 수 있는 방식이다. 하지만 무조건 인터럽트가 폴링보다 좋다고 할 수는 없다. 예를 들어 어떤 작업이 단 한 번의 폴링으로 끝날 정도의 작업이라면 인터럽트보다는 폴링이 더 효율적이다. 왜냐하면 인터럽트 사용 시 현재 실행중인 프로세스로부터 다른 프로세스로의 문맥교환이 일어나고, 이 때 많은 비용이 들기 때문이다.
빠른 하드웨어 장치라면 폴링, 느린 하드웨어 장치라면 인터럽트가 더 효율적이다.

</aside>

### 직접 메모리 접근(DMA, Direct Memory Access)

참고: [https://ko.wikipedia.org/wiki/직접_메모리_접근](https://ko.wikipedia.org/wiki/%EC%A7%81%EC%A0%91_%EB%A9%94%EB%AA%A8%EB%A6%AC_%EC%A0%91%EA%B7%BC)

과거의 운영체제는 폴링 방식을 사용했기 때문에 CPU가 메모리나 주변장치에 대한 모든 권한을 가지고 있었다. 현대의 운영체제는 효율성을 높이기 위해 소프트웨어적인 방식인 폴링  대신 하드웨어 방식인 인터럽트를 사용하게 되었고, 이로 인해 입출력 관리자가 데이터의 입출력을 맡게 되었다.

입출력이 필요한 상황을 가정해보자. CPU는 입출력 관리자에게 입출력 요청을 보낸다. 요청을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다 놓아야 한다. 그런데 메모리 접근 권한은 CPU만 가지고 있어 입출력 관리자가 메모리에 접근할 때마다 CPU의 개입이 필요하다. 이러한 개입이 필요하다면, CPU가 입출력 관리자에게 입출력 요청을 보내고 자신은 하던 일을 계속하는 행위는 불가능하기 때문에 비효율적이다.

따라서 **입출력 관리자가 CPU의 개입 없이 데이터의 입출력을 수행하기 위해서는, CPU의 허락 없이 메모리에 접근할 수 있는 권한을 가져야 한다. 이러한 권한을 DMA라고 한다.**

DMA를 사용하면 CPU에는 데이터 이동이 완료되었다는 단 한 번의 인터럽트만 발생하여 효율적이다.

### 메모리 매핑 입출력

DMA를 통해 들어온 데이터를 아무렇게나 메모리에 아무렇게나 둔다면, CPU가 사용하는 데이터와 입출력 장치가 사용하는 데이터가 섞여 관리하기 어렵다. 메모리 매핑 입출력은 이를 해결하기 위해 도입됐다.

메모리 매핑 입출력은 **CPU가 사용하는 메모리 공간과 입출력을 위한 메모리 공간을 분리하기 위해, 메모리의 일정 공간을 입출력에 할당하는 기법이다.**

### 사이클 훔치기

CPU와 DMA가 동시에 메모리에 접근하려 하는 상황이 생긴다면, 보통 CPU가 메모리 사용 권한을 양보한다. 이는 CPU의 작업 속도보다 I/O 장치의 속도가 느리기 때문이다. 이러한 상황을 CPU 입장에서 보면, DMA가 사이클을 훔친 것이기 때문에, 사이클 훔치기라 부른다.

# 병렬 처리

동시에 여러 개의 명령을 처리하여 작업의 능률을 올리는 방식이다. 하나의 CPU 코어가 여러 개의 스레드를 이용하는 방식과 여러 개의 CPU 코어가 존재하는 방식이 있다.

## 병렬 처리 시 고려 사항

- 상호 의존성이 없어야 병렬 처리가 가능하다. 각 명령은 서로 독립적이고, 앞의 결과가 뒤의 명령에 영향을 미치지 않아야 한다.
- 각 단계의 시간을 거의 일정하게 맞춰야 병렬 처리가 원만하게 이뤄진다.
- 전체 작업 시간을 몇 단계로 쪼갤지 잘 따져봐야 한다. 일차원적으로 생각하면 작업을 많이 쪼갤수록 동시에 할 수 있는 작업의 개수가 많아져서 성능이 높아진다. 하지만 작업을 많이 쪼갤수록 각 단계마다 작업을 이동시키고 불러오는 데 많은 시간이 걸리기 때문에 오히려 성능이 떨어질 수 있다. 이러한 오버헤드를 고려하여 보통은 병렬 처리의 깊이를 10~20정도로 한다.

## 병렬 처리 기법

CU가 명령어를 가져와 해석한 후 실행하고 결과를 저장하는 과정 전체를 하나의 스레드라고 한다. 스레드를 이루는 각 단계는 CPU의 클록과 연동되어 한 클록에 한 번씩 이루어진다.

**명령어 처리 4단계의 예(꼭 4단계일 필요는 없고, 경우에 따라 다르다.)**

1. 명령어 패치(IF): 다음에 실행할 명령어를 IR에 저장
2. 명령어 해석(ID): 명령어 해석
3. 실행(EX): 해석한 결과를 토대로 명령어 실행
4. 쓰기(WB): 실행된 결과를 메모리에 저장

### 파이프라인 기법

참고: [https://ko.wikipedia.org/wiki/명령어_파이프라인](https://ko.wikipedia.org/wiki/%EB%AA%85%EB%A0%B9%EC%96%B4_%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8)

![https://upload.wikimedia.org/wikipedia/commons/2/21/Fivestagespipeline.png](https://upload.wikimedia.org/wikipedia/commons/2/21/Fivestagespipeline.png)

CPU의 사용을 극대화하기 위해 **명령을 겹쳐서 실행**하는 방법이다. 1개의 코어에 여러 개의 스레드를 사용한다. **명령어를 여러 단계로 분할한 후, 각 단계를 동시에 처리**하는 하드웨어를 독립적으로 구성한다.

기존 방식: 명령어 하나를 처리하기 위해 명령어 처리 4단계를 모두 마친 뒤 다음 명령어를 실행한다.

파이프라인 기법: **각 단계가 쉬지 않고 명령어를 처리한다.**

인텔 계열의 CPU에서는 파이프라인 기법을 하이퍼스레드라고 한다. 하이퍼스레드는 CPU에 여러 개의 작업을 동시에 진행할 수 있는 부가장치를 만들어 하나의 코어에서도 여러 개의 작업이 동시에 이뤄지게 하는 기법이다.

**문제점(파이프라인의 위험)**

참고: [https://en.wikipedia.org/wiki/Hazard_(computer_architecture)](https://en.wikipedia.org/wiki/Hazard_(computer_architecture))

- 데이터 위험: 데이터 의존성 때문에 발생한다. 첫 번째 명령어의 산출물인 어떤 데이터를 필요로 하는 두 번째 명령어는 앞의 명령어가 끝날 때까지 동시에 실행돼서는 안 된다. 이 위험은 파이프라인의 명령어 단계를 지연하여 해결한다.

```nasm
명령어 1: R5 <- R1 + R3
명령어 2: R6 <- R4 + R5
```

- 제어 위험: 분기를 하는 if문, 떨어진 곳으로 이동하는 goto문 같은 명령에서 PC 값을 갑자기 변화시켜 발생한다. 예를 들어, 보통의 경우 모든 프로그램이 순차적으로 실행된다고 가정하므로, 동시에 실행되는 명령어들이 순차적으로 실행된다. 그러나 첫 명령어를 실행하고 보니 goto문이어서 바로 다음 명령어가 아니라 멀리 떨어진 명령어로 이동하게 되면 현재 동시에 처리되고 있는 명령어들이 쓸모없어진다. 이러한 위험은 분기 예측이나 분기 지연 방법으로 해결한다.
- 구조 위험: 서로 다른 명령어가 같은 자원에 접근하려 할 때 발생하는 문제이다. 예를 들어 어떤 명령어가 레지스터 1을 사용하고 있는데, 다른 명령어도 레지스터 1을 사용해야 할 때 서로 충돌하게 되는 것이다. 이러한 위험은 해결하기 어렵다.

### 슈퍼스칼라 기법

참고: [https://en.wikipedia.org/wiki/Superscalar_processor](https://en.wikipedia.org/wiki/Superscalar_processor)

![https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Superscalarpipeline.svg/1200px-Superscalarpipeline.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Superscalarpipeline.svg/1200px-Superscalarpipeline.svg.png)

**파이프라인을 처리할 수 있는 코어를 여러 개 구성하여 복수의 명령어가 동시에 실행되도록 하는 기법**이다. 코어 자체를 여러 개 구성하기 때문에 각 단계에서 동시에 실행되는 명령어가 여러 개이다.

### 슈퍼파이프라인 기법

파이프라인 기법을 강화한 것이다. 파이프라인 기법에서는 한 클록마다 하나의 명령어를 실행하지만, 슈퍼파이프라인 기법에서는 **파이프라인의 각 단계를 세분하여 한 클럭 내에 여러 개의 명령어를 처리할 수 있다.** 이 때문에 병렬 처리 능력이 높아진다. 슈퍼파이프라인 기법을 활용한 예로는 크레이 슈퍼컴퓨터의 CPU가 있다.

### 슈퍼파이프라인 슈퍼스칼라 기법

파이프라인·슈퍼스칼라·슈퍼파이프라인 기법을 모두 합쳐놓은 것이다. 슈퍼파이프라인 기법을 여러 개의 코어에서 동시에 수행하는 방식이다.

### VLIW(Very Long Instruction Word) 기법

앞의 병렬 처리 기법들은 CPU가 병렬 처리를 지원하는 기법들이다. VLIW 기법은 CPU가 병렬 처리를 지원하지 않을 경우 소프트웨어적으로 병렬 처리를 하는 기법이다. VLIW 기법에서는 동시에 수행할 수 있는 명령어들을 컴파일러가 추출하고 하나의 명령어로 압축해서 실행한다.

 VLIW 기법을 활용할 경우 CPU가 지원하는 병렬 처리 기법을 활용하는 경우에 비해 동시에 처리하는 명령의 수가 적다. 또한, CPU가 지원하는 병렬 처리 기법들은 명령어 실행 시 병렬 처리가 이뤄지지만, VLIW 기법은 컴파일 시 병렬 처리가 이뤄진다.

# 무어의 법칙과 암달의 법칙

## 무어의 법칙

CPU의 속도가 24개월마다 2배 빨라진다는 법칙으로, 인텔의 공동 창업자인 고든 무어가 주장했다. 이 주장은 초기의 CPU에만 적용되며 지금은 그렇지 않다.

CPU는 자체 발열 문제로 속도를 5GHz 이상 높이기 어려워 요즘은 처리 속도를 올리는 대신 멀티 코어를 장착하는 방향으로 나아가고 있다.

## 암달의 법칙

컴퓨터 시스템의 일부를 개선할 때 전체 시스템에 미치는 영향과의 관계를 수식으로 나타낸 법칙으로, 진 암달이 만들었다. 이 법칙은 주변장치의 향상없이 CPU의 속도만을 2배 늘린다고 해서 컴퓨터가 2배 빨라지지는 않는다는 법칙이다. 또한, 암달의 법칙은 CPU 내부에도 적용되는데, CPU의 코어를 2배로 늘려도 CPU 내 다른 부품들의 병목 현상으로 인해, CPU 성능이 2배가 되지는 않는다.

- 질문 목록
    - 캐시의 지역성이 뭔가요?
        - 지역성의 관점에서 퀵 소트와 머지 소트의 성능을 비교해 주세요.
    - 인터럽트 동작 과정을 설명해 주세요.
    - 폴링에 대해 설명해 주세요.
    - DMA의 목적이 뭔가요?
    - 병렬 처리 기법 중 파이프라인 기법에 대해 설명해 주세요.

노션 링크: https://babybeb.notion.site/CHAPTER-02-da9ffdad94cb44c2b8a1c4df5eafb498